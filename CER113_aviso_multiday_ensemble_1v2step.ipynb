{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9dedb-abc6-4fd0-b91f-0d10bd1297fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▊                         | 84/210 [08:56<09:35,  4.56s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import gsw\n",
    "import xarray as xr\n",
    "import cmocean as cmo\n",
    "from numpy import linalg as LA\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from tqdm import tqdm\n",
    "from aviso_rossby_wave import skill_matrix, build_h_matrix\n",
    "from aviso_rossby_wave import reverse_vector, forecast_ssh\n",
    "from aviso_rossby_wave import build_swath, inversion, inversion2, make_error_over_time\n",
    "import glob2 as glob\n",
    "\n",
    "\n",
    "day0, day1 = 0, 30 # 150 day assimilation\n",
    "Tdim = day1 - day0\n",
    "start_date = '2016-06-01' ## starting date\n",
    "n_waves = '190' #number of waves\n",
    "exp = 1 # P_over_R = K^-1\n",
    "MModes = 1 # Rossby wave vertical modes\n",
    "wave_files = glob.glob('./rossby_wave_estimate_*_' + n_waves + 'waves.nc')\n",
    "wave_files = sorted(wave_files)\n",
    "\n",
    "alpha_std = np.arange(5e-4, 3.05e-2, 1e-3) # standard deviation of error paramters\n",
    "\n",
    "lonidx_west, lonidx_east  =  60, 100\n",
    "latidx_south, latidx_north = 34, 74\n",
    "\n",
    "avisso_ds = xr.open_dataset('./aviso_msla_ccs_5d.nc')\n",
    "SSHA = avisso_ds.msla[latidx_south:latidx_north,lonidx_west:lonidx_east, :]\n",
    "lon, lat = (360 - avisso_ds.lon[lonidx_west:lonidx_east].data) * -1, avisso_ds.lat[latidx_south:latidx_north].data\n",
    "T_time = avisso_ds.time.data[day0:] * 86400 # in seconds\n",
    "date_time = avisso_ds.date_time.data[day0:]\n",
    "\n",
    "rms_err, rms_ssh = np.zeros([len(wave_files), len(alpha_std)]), np.zeros([len(wave_files), len(alpha_std)])\n",
    "\n",
    "ssh_est_skill2, err_est_skill2 = np.zeros([len(wave_files), len(alpha_std)]), np.zeros([len(wave_files), len(alpha_std)])\n",
    "\n",
    "ssh_est_skill1, err_est_skill1 = np.zeros([len(wave_files), len(alpha_std)]), np.zeros([len(wave_files), len(alpha_std)])\n",
    "\n",
    "with tqdm(total= rms_err.size) as pbar:\n",
    "    for n in range(len(wave_files)):\n",
    "        wave_ds = xr.open_dataset(wave_files[n]) # forward model - filtered AVISO\n",
    "        l_n_orig, k_n_orig = wave_ds.l_n.data, wave_ds.k_n.data\n",
    "        amp = wave_ds.Amplitudes.data\n",
    "        time= wave_ds.time.data\n",
    "        MSLA_fwd = wave_ds.MSLA_forward.data\n",
    "        Rm = wave_ds.Rm.data # Rossby deformation radius, unit: degree\n",
    "        l_n_orig, k_n_orig = wave_ds.l_n.data, wave_ds.k_n.data\n",
    "        amp = wave_ds.Amplitudes.data\n",
    "        time= wave_ds.time.data\n",
    "        MSLA_fwd = wave_ds.MSLA_forward.data\n",
    "        Rm = wave_ds.Rm.data # Rossby deformation radius, unit: degree\n",
    "\n",
    "        Phi0 = lat.mean() # central latitude (φ0)\n",
    "        Omega = 7.27e-5 # Ω is the angular speed of the earth\n",
    "        Earth_radius = 6.371e6 / 1e5 # meters\n",
    "        Beta = 2 * Omega * np.cos(Phi0) / Earth_radius\n",
    "        f0 = 2 * Omega * np.sin(Phi0) #1.0313e-4 # 45 N\n",
    "\n",
    "        strat_ds = xr.open_dataset('./stratification_sample_ccs.nc')\n",
    "        Psi = strat_ds.Psi.data\n",
    "\n",
    "        l_n = l_n_orig.reshape(len(l_n_orig), MModes)\n",
    "        k_n = k_n_orig.reshape(len(k_n_orig), MModes)\n",
    "\n",
    "        MSLA0 = MSLA_fwd[:, :, day0:day1]\n",
    "\n",
    "        ### assess skill, get indices\n",
    "        skill, SSHA_vector, Iindex, Jindex, Tindex = skill_matrix(MSLA0, Psi, l_n, k_n, MModes, Rm, lon, lat, T_time) # skill marrix\n",
    "\n",
    "        M = k_n.size * l_n.size # Number of models/waves\n",
    "\n",
    "        dlon = lon - lon.mean()\n",
    "        dlat = lat - lat.mean()\n",
    "\n",
    "        H_cos, H_sin = np.zeros([len(SSHA_vector), M]), np.zeros([len(SSHA_vector), M])\n",
    "        H_all = np.zeros([len(SSHA_vector), M * 2])\n",
    "        omega = np.zeros([len(l_n), len(k_n), MModes])\n",
    "\n",
    "        nn = 0\n",
    "        for kk in range(len(l_n)):\n",
    "            for ll in range(len(k_n)):\n",
    "                for mm in range(MModes):\n",
    "                    omega[kk, ll, mm] =  -(Beta * l_n[kk, mm]) / (l_n[kk, mm] ** 2 + k_n[ll, mm] ** 2 + Rm ** -2)\n",
    "                    for count in range(len(Iindex)):\n",
    "                        # (data, model)\n",
    "                        H_cos[count, nn] = Psi[0, mm] * np.cos(k_n[ll, mm] * dlon[int(Iindex[count])] + l_n[kk, mm] * dlat[int(Jindex[count])] - omega[kk, ll, mm] * T_time[int(Tindex[count])])\n",
    "                        H_sin[count, nn] = Psi[0, mm] * np.sin(k_n[ll, mm] * dlon[int(Iindex[count])] + l_n[kk, mm] * dlat[int(Jindex[count])] - omega[kk, ll, mm] * T_time[int(Tindex[count])])\n",
    "                    nn += 1\n",
    "\n",
    "        H_all[:, 0::2] = H_cos\n",
    "        H_all[:, 1::2] = H_sin\n",
    "\n",
    "        # signal to noise ratio R_over_P\n",
    "\n",
    "        counter = 0\n",
    "        exp = -2\n",
    "        ssh_std = .1\n",
    "        k0 = l_n.max() # flat at or below k0\n",
    "\n",
    "        p_diagonal = np.zeros([2 * M])\n",
    "        kl, kl_plot = np.zeros(M), np.zeros(2*M)\n",
    "        k_, l_ = np.zeros(len(l_n)*len(k_n)), np.zeros(len(l_n)*len(k_n))\n",
    "        counter = 0\n",
    "        R = 0.01 # noise = 1. cm\n",
    "\n",
    "        for kk in l_n:\n",
    "            for ll in k_n:\n",
    "                k_[counter] , l_[counter]  = kk, ll\n",
    "                kl[counter] =  np.sqrt(kk ** 2 + ll ** 2) # wavenumber\n",
    "                kl_plot[2 * counter], kl_plot[2 * counter + 1] = kl[counter], kl[counter]\n",
    "                p_diagonal[2 * counter] = (kl[counter]+k0) ** exp\n",
    "                p_diagonal[2 * counter + 1] = (kl[counter]+k0) ** exp\n",
    "                counter += 1\n",
    "\n",
    "        P_matrix = np.zeros([2 * M, 2 * M])\n",
    "        p_factor = .16/p_diagonal.sum() # variance of the model,  convert sum of variance from waven number to meter\n",
    "        np.fill_diagonal(P_matrix[:],  R / p_diagonal / p_factor)\n",
    "\n",
    "        ## build satellite swath\n",
    "\n",
    "        swath_width, x_swath = 6, 20\n",
    "        days = np.arange(day0, day1)\n",
    "        xvalid_index, yvalid_index, tindex, yswath_index_left, yswath_index_right, y_mask_left, y_mask_right = build_swath(swath_width, x_swath, days, lon, lat)\n",
    "\n",
    "        # Loop over sigma\n",
    "        sigma_counter = 0\n",
    "        \n",
    "        for sigma in alpha_std: # std of error amp\n",
    "\n",
    "            # Add errors to the swaths\n",
    "            mu = 0\n",
    "            time_factor = np.arange(1, 1 + day1-day0)\n",
    "            # generate error parameter with Gaussian distribution\n",
    "            alpha = np.zeros([Tdim, 7]) #np.random.normal(mu, sigma, Tdim * 7).reshape(Tdim, 7) #\n",
    "            for nn in range(7):\n",
    "                alpha[:, nn] = np.random.normal(mu, sigma, Tdim) #TEST\n",
    "\n",
    "            timing_err_valid, roll_err_valid, baseline_dilation_err_valid, phase_err_valid, xc1_valid, xc2_valid  = make_error_over_time(days, alpha, yswath_index_left, yswath_index_right, y_mask_left, y_mask_right)\n",
    "\n",
    "            # sample SSH, errors and add white noise\n",
    "            IND_TIMING = -7\n",
    "            IND_ROLL = -6\n",
    "            IND_BASELINE = -5\n",
    "            IND_PHASE3, IND_PHASE4, IND_PHASE5, IND_PHASE6 = -4, -3, -2, -1\n",
    "\n",
    "            #### Sub-sample the SSH, correlated errors and H matrix\n",
    "            N = len(tindex) # number of data\n",
    "            MSLA_swath = np.zeros(N)\n",
    "            M = l_n.size * k_n.size\n",
    "            nx, ny = len(lon), len(lat)\n",
    "            H_swath = np.zeros([N, 2 * M + Tdim * 7]) # M: number of model\n",
    "            IIndex = np.zeros(N) # N: Number of y data\n",
    "            cor_err = np.zeros(N) # Correlated Error N: Number of y data\n",
    "            Y_v = np.zeros(N)\n",
    "            ssh = np.zeros(N)\n",
    "\n",
    "            for ii in range(N):\n",
    "                IIndex[ii] = nx * ny * tindex[ii] + ny * xvalid_index[ii] + yvalid_index[ii] # index in the vector space\n",
    "                ssh[ii] = MSLA_fwd[xvalid_index[ii], yvalid_index[ii], int(tindex[ii])]\n",
    "                cor_err[ii] = timing_err_valid.flatten()[ii] + roll_err_valid.flatten()[ii] + baseline_dilation_err_valid.flatten()[ii] + phase_err_valid.flatten()[ii]\n",
    "                MSLA_swath[ii] = ssh[ii] + cor_err[ii] # filtered AVISO SSH , no error along the satellite passings\n",
    "                for nn in range(M):\n",
    "                    JIndex = 2 * MModes * nn # +  2 * mm # Model space\n",
    "                    H_swath[ii, JIndex] = H_cos[IIndex[ii].astype(int), nn]\n",
    "                    H_swath[ii, JIndex + 1] = H_sin[IIndex[ii].astype(int), nn]\n",
    "\n",
    "            Valid_points = len(xvalid_index) // Tdim\n",
    "            err_basis_func = np.zeros([Valid_points, 7])\n",
    "            for tt in range(Tdim):\n",
    "                for ii in range(Valid_points):\n",
    "                    #timing error\n",
    "                    err_basis_func[ii, IND_TIMING] = 1 #  alpha_timing, TIMING ERR, distance from nadir Xc\n",
    "                    # roll error = alpha[1] * Xc^1\n",
    "                    err_basis_func[ii, IND_ROLL] = xc1_valid[tt, ii]  # alpha_roll, ROLL ERR, distance from nadir Xc\n",
    "                    # baseline dialation error = alpha[2] * Xc^2\n",
    "                    err_basis_func[ii, IND_BASELINE] = xc2_valid[tt, ii]  # alpha_base, BASELINE DIALATION ERR, distance from nadir Xc\n",
    "                    # phase error\n",
    "                    H_neg = np.heaviside(-1 * xc1_valid[tt, ii], 1) #\n",
    "                    H_pos = np.heaviside(xc1_valid[tt, ii], 1) #\n",
    "                    err_basis_func[ii, IND_PHASE3] = H_neg                 # alpha_phase3 * np.heaviside(xx - xc, 1)\n",
    "                    err_basis_func[ii, IND_PHASE4] = xc1_valid[tt, ii] * H_neg # alpha_phase4 * Xc * np.heaviside(xx - xc, 1)\n",
    "                    err_basis_func[ii, IND_PHASE5] = H_pos                 # alpha_phase5 * np.heaviside(xx + xc, 1)\n",
    "                    err_basis_func[ii, IND_PHASE6] = xc1_valid[tt, ii] * H_pos # alpha_phase6 * np.heaviside(xx + xc, 1)\n",
    "\n",
    "            ### fill the error basis function part of the H matrix\n",
    "            for tt in range(Tdim):\n",
    "                #print(2 * M + tt * 7 , 2 * M + (tt+1) * 7)\n",
    "                H_swath[tt*Valid_points:(tt+1)*Valid_points, 2 * M + tt * 7 : 2 * M + (tt+1) * 7] = err_basis_func\n",
    "\n",
    "            counter = 0\n",
    "            exp = -2\n",
    "            ssh_std = .1\n",
    "            k0 = l_n.max() # flat at or below k0\n",
    "            p_diagonal = np.zeros([2 * M + Tdim * 7])\n",
    "            kl, kl_plot = np.zeros(M), np.zeros(2*M)\n",
    "            k_, l_ = np.zeros(M), np.zeros(M)\n",
    "            counter = 0\n",
    "            R = 0.01 # noise = 10. cm\n",
    "\n",
    "            for kk in l_n:\n",
    "                for ll in k_n:\n",
    "                    k_[counter] , l_[counter]  = kk, ll\n",
    "                    kl[counter] =  np.sqrt(kk ** 2 + ll ** 2) # wavenumber\n",
    "                    kl_plot[2 * counter], kl_plot[2 * counter + 1] = kl[counter], kl[counter]\n",
    "                    p_diagonal[2 * counter] = (kl[counter] + k0) ** exp  * p_factor\n",
    "                    p_diagonal[2 * counter + 1] = (kl[counter] + k0) ** exp  * p_factor\n",
    "                    counter += 1\n",
    "\n",
    "            p_diagonal[2*M:] = sigma ** 2 # errors\n",
    "\n",
    "            P_matrix = np.zeros([2 * M + Tdim * 7, 2 * M +  Tdim * 7])\n",
    "\n",
    "            np.fill_diagonal(P_matrix[:],  R / p_diagonal )\n",
    "\n",
    "            Y_vector = Y_v\n",
    "            H_matrix = H_swath\n",
    "\n",
    "            # 1-stage approach, solve for amplitudes\n",
    "            amp_swath, msla_estimated_swath = inversion(MSLA_swath, H_swath, P_matrix) # assimilate the filtered AVISO SSH + error\n",
    "\n",
    "            # estimate the errors and ssh : H * amp\n",
    "            err_est_1step = np.matmul(H_matrix[:, -7*Tdim:], amp_swath[-7*Tdim:])\n",
    "            ssh_est_1step = np.matmul(H_matrix[:, :-7*Tdim], amp_swath[:-7*Tdim])\n",
    "\n",
    "            # Important result: error estimate skill and ssh estimate skill of the entire time series\n",
    "            ssh_diff = ssh_est_1step - ssh\n",
    "            err_diff = err_est_1step - cor_err\n",
    "            ssh_diff1 = np.sqrt(np.mean(ssh_diff**2)) / np.sqrt(np.mean(ssh**2))\n",
    "            err_diff1  = np.sqrt(np.mean(err_diff**2)) / np.sqrt(np.mean(cor_err**2))\n",
    "\n",
    "            HTH = np.matmul(H_matrix[:, -7 * Tdim:].T, H_matrix[:, -7 * Tdim:])\n",
    "\n",
    "            # Two-stage approach: reconstructing the SSH separately from solving the correlated error\n",
    "\n",
    "            # First step: fit errors\n",
    "            H_v1 = H_swath[:, -7 * Tdim:]\n",
    "            P_over_R1 = P_matrix[-7* Tdim:, -7* Tdim:]\n",
    "            HTH = np.matmul(H_v1.T, H_v1)\n",
    "            HRH = HTH + P_over_R1 # P: uncertainty in model, R: uncertainty in data\n",
    "            D = np.matmul(LA.inv(HRH), H_v1.T)\n",
    "            amp_err = np.matmul(D, MSLA_swath)\n",
    "\n",
    "            err_est_2step = np.matmul(H_v1, amp_err) #### estimate the correlated error\n",
    "\n",
    "            # second step: fit residual to rossby wave models\n",
    "\n",
    "            H_v = H_swath[:, :-7 * Tdim]\n",
    "            HTH = np.matmul(H_v.T, H_v)\n",
    "            HRH = np.zeros(HTH.shape)\n",
    "            HRH = HTH +  P_matrix[:-7 * Tdim, :-7 * Tdim]\n",
    "            D = np.matmul(LA.inv(HRH), H_v.T)\n",
    "            eig, vec = LA.eig(HRH)\n",
    "\n",
    "            # second step: fit residual to rossby wave models\n",
    "            tau_ssh = MSLA_swath - err_est_2step\n",
    "            amp_swath_2step = np.matmul(D, tau_ssh)\n",
    "            ssh_est_2step = np.matmul(H_v, amp_swath_2step) #### Reconstruct ssh with new amplitudes in the next 40 days\n",
    "\n",
    "            # Important result: 2-stage error estimate skill and ssh estimate skill\n",
    "            ssh_diff = ssh_est_2step - ssh\n",
    "            err_diff = err_est_2step - cor_err\n",
    "            ssh_diff_2stage = np.sqrt(np.mean(ssh_diff ** 2)) / np.sqrt(np.mean(ssh ** 2))\n",
    "            err_diff_2stage = np.sqrt(np.mean(err_diff ** 2)) / np.sqrt(np.mean(cor_err ** 2))\n",
    "\n",
    "            # Root mean squared err/ssh\n",
    "            rms_err[n, sigma_counter] = np.sqrt(np.mean(cor_err ** 2))\n",
    "            rms_ssh[n, sigma_counter]= np.sqrt(np.mean(ssh ** 2))\n",
    "\n",
    "            # Important result: 2-stage error estimate skill and ssh estimate skill\n",
    "            ssh_est_skill2[n, sigma_counter], err_est_skill2[n, sigma_counter] = (1 - ssh_diff_2stage.mean()) * 100, (1 - err_diff_2stage.mean()) * 100 # percentage,\n",
    "\n",
    "            # Important result: 1-stage error estimate skill and ssh estimate skill\n",
    "            ssh_est_skill1[n, sigma_counter], err_est_skill1[n, sigma_counter] = (1 - ssh_diff1.mean()) * 100, (1 - err_diff1.mean()) * 100 # percentage,\n",
    "\n",
    "            sigma_counter += 1\n",
    "\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752a5d9-0ee1-4d2c-ac51-cb3dca87845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_over_rmssh = rms_err / rms_ssh\n",
    "ratio_mean = rmse_over_rmssh.mean(axis = 0)\n",
    "ssh_est_skill2_mean = ssh_est_skill2.mean(axis = 0)\n",
    "ssh_est_skill1_mean = ssh_est_skill1.mean(axis = 0)\n",
    "err_est_skill1_mean = err_est_skill1.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992be04-0187-47bd-a5d7-c2961b384461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show error estimate skill greater than -100%\n",
    "err_est_skill1 = np.ma.masked_less(err_est_skill1, -100)\n",
    "err_est_skill2 = np.ma.masked_less(err_est_skill2, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a14a2-c275-4883-854c-3b14a985804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, figsize=(10, 8))\n",
    "\n",
    "# Plot data\n",
    "axs[0].scatter(rmse_over_rmssh , ssh_est_skill2, marker='x', label='Two-stage')\n",
    "axs[0].scatter(rmse_over_rmssh , ssh_est_skill1, marker='*', label='One-stage')\n",
    "\n",
    "axs[1].scatter(rmse_over_rmssh , err_est_skill2, marker='x', label='Two-stage')\n",
    "axs[1].scatter(rmse_over_rmssh , err_est_skill1, marker='*', label='One-stage')\n",
    "\n",
    "# Label axes\n",
    "axs[0].set_xlabel('Ratio (RMSE/RMSSH)')\n",
    "axs[0].set_ylabel('Skill in SSH estimate')\n",
    "axs[1].set_xlabel('Ratio (RMSE/RMSSH)')\n",
    "axs[1].set_ylabel('Skill in Error estimate')\n",
    "\n",
    "# Add titles\n",
    "# axs[0].set_title('Skill in SSH estimate for different RMSE values')\n",
    "# axs[1].set_title('Skill in Error estimate for different RMSE values')\n",
    "\n",
    "# Add legends\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('skill_ssh_errr_rmse_ratio.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e864bd8-84d7-4438-9899-b45e5fd0522a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_over_rmssh = rms_err / rms_ssh\n",
    "ratio_mean = rmse_over_rmssh.mean(axis = 0)\n",
    "ssh_est_skill2_mean = ssh_est_skill2.mean(axis = 0)\n",
    "ssh_est_skill1_mean = ssh_est_skill1.mean(axis = 0)\n",
    "err_est_skill1_mean = err_est_skill1.mean(axis = 0)\n",
    "err_est_skill2_mean = err_est_skill2.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be009d3c-0065-4e56-8a4b-b0b8e2d8555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show error estimate skill greater than -100%\n",
    "err_est_skill1_mean = np.ma.masked_less(err_est_skill1_mean, -100)\n",
    "err_est_skill2_mean = np.ma.masked_less(err_est_skill2_mean, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccfc42c-54bf-4d0f-846d-2a764cd80ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, figsize=(10, 8))\n",
    "\n",
    "# Plot data\n",
    "axs[0].scatter(rmse_over_rmssh, ssh_est_skill2, marker='x', label='Two-stage')\n",
    "axs[0].scatter(rmse_over_rmssh , ssh_est_skill1, marker='*', label='One-stage')\n",
    "axs[0].plot(ratio_mean , ssh_est_skill2_mean, linestyle = '-.', color = 'b', label='Two-stage ensemble mean')\n",
    "axs[0].plot(ratio_mean, ssh_est_skill1_mean, linestyle = '--', color = 'r', label='One-stage ensemble mean')\n",
    "\n",
    "\n",
    "axs[1].scatter(rmse_over_rmssh , err_est_skill2, marker='x', label='Two-stage')\n",
    "axs[1].scatter(rmse_over_rmssh , err_est_skill1, marker='*', label='One-stage')\n",
    "axs[1].plot(ratio_mean , err_est_skill2_mean, linestyle = '-.', color = 'b', label='Two-stage ensemble mean')\n",
    "axs[1].plot(ratio_mean , err_est_skill1_mean, linestyle = '--', color = 'r', label='One-stage ensemble mean')\n",
    "\n",
    "# Label axes\n",
    "axs[0].set_xlabel('Ratio (RMSE/RMSSH)')\n",
    "axs[0].set_ylabel('Skill in SSH estimate')\n",
    "axs[1].set_xlabel('Ratio (RMSE/RMSSH)')\n",
    "axs[1].set_ylabel('Skill in Error estimate')\n",
    "\n",
    "# Add titles\n",
    "axs[0].set_title('a) Skill in SSH estimate for different RMSE values')\n",
    "axs[1].set_title('b) Skill in Error estimate for different RMSE values')\n",
    "\n",
    "# Add legends\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "# Show plots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('skill_ssh_errr_rmse_ratio_mean.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0468d-c4bb-498b-83a8-5810ad6a94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_mean * 100, alpha_std, rmse_over_rmssh[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc512020-ab20-4620-ba1f-f55b4d5be77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_est_skill2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376d6ee-503a-4b4e-aba5-85c38c7e7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_est_skill1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0200bd8-8ff0-43d8-851e-93a78687c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_est_1step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445456aa-6928-4d69-bcc1-58692e65225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean error in meters\n",
    "rms_err.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1d168-cc3f-4fa4-8d01-0a588dd81e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est_skill1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea1274-e691-4067-9997-d7c817442aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342ab2a-c68f-4938-b3b4-50f315d58144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e86241-e59d-4c36-ac6a-f46aacdb00f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1bd73-cf17-4d01-8a5b-094ae1ce3c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66f05c-b1d7-41af-abfb-eb6605bfc219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c0257-4821-41b7-a494-2adfc265f2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb0058-a62e-420d-85d3-7aadc8b781fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d0e6b-6d66-49fb-9a12-74354c5aa722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea432f-6277-4844-becc-98bc6ffd4414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47dd85-031c-44bc-b19a-d2f69b122145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7219c-649f-43fe-8b0d-c57a5a4bc89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdbb8b-925f-4e21-862c-7d1cb2e0c8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354588b-dc99-438f-a61a-bb166795219d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34029497-6985-4811-9d88-6d8212053174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
